import DemoDitherZoom from './DemoDitherZoom';
import DemoDitherRGB from './DemoDitherRGB';
import DemoThreshold from './DemoThreshold';
import DemoRandom from './DemoRandom';
import DemoRandomGraph from './DemoRandomGraph';
import DemoPattern from './DemoPattern';
import DemoPatternImage from './DemoPatternImage';
import DemoOrdered from './DemoOrdered';
import ImageGrid from './ImageGrid';

# Dithering: a visual introduction

## What is dithering?

Dither is noise introduced to an image to reduce large-scale patterns like color banding when using a limited color palette. In other words, it's a way to trick the eye into seeing more colors than are actually being displayed.

The human eye can only see detail up to a certain point, beyond which it starts to blur things together. The image below is a grid of alternating black and white tiles. Try zooming all the way out by dragging the Zoom slider to the left:

<DemoDitherZoom showZoom />

At larger sizes, the tiles are clearly visible, but as you zoom out they start to blend together into gray. This is an illusion: your display is really only showing pure black and white pixels, but your eyes can't see that much detail and instead mix together equal parts black and white into gray.

The last example used an equal amount of black and white tiles, resulting in a 50% gray. We can change the shade of the perceived color by making more or fewer of the “tiles” or pixels black or white. Try moving the brightness slider toward both ends:

<DemoDitherZoom showZoom showRatio="Brightness" />

By altering the _ratio_ of white to black pixels, we can make the resulting gray brighter or darker. More white pixels make the rectangle lighter on average, and so it looks brighter, while more black pixels make it darker. At each end, all pixels are either black or white and that's the color you see.

This doesn't just work for black and white, rather, we can use it to “mix” any two colors:

<DemoDitherZoom showZoom showRatio="Balance" color1="blue" color2="red" />

And the effect isn't limited to just two colors, either. In the example below, black is mixed with the three RGB primaries to approximate almost any color. You can play around with the RGB sliders to change the “target” color we're trying to match, which is shown in the box at the top.

<DemoDitherRGB />

This is the working principle of dithering: by mixing a few base colors in tiny patterns, we can trick our eyes into seeing the shades in between that we can't actually display.

## Why dithering?

Modern displays and image formats can display some 16.7 _million_ colors. That's a lot. This hasn't always been the case, though. Back in the early days of computers, most devices had monochrome screens with only a few brightness levels. Early color displays supported as few as 16 or even just _four_ colors at a time. Even as late as the early 2000s there were still people using 256-color displays—hence the 216-color “web safe” palette—and some popular image formats were limited to a 256 color palette as well.

In these low-color scenarios, dithering helps reduce color banding and effectively increases the number of colors we can display. Generally speaking, dithered images just look much better (click each image to view in detail):

<ImageGrid
  basePath="/Documents/Articles/assets/dither/"
  images={[
    {
      src: 'boat-original',
      formats: ['webp', 'jpeg'],
      alt: 'Original image',
      caption: '24-bit “true color”',
    },
    {
      src: 'boat-web',
      formats: ['webp', 'jpeg'],
      alt: 'Web safe image',
      caption: 'Web safe palette (216 colors)',
    },
    {
      src: 'boat-web-dither',
      formats: ['webp', 'jpeg'],
      alt: 'Dithered image',
      caption: 'Web safe palette, dithered',
    },
  ]}
/>

These days, most displays are capable of showing _at least_ 16.7 million colors, and modern compression algorithms are [far more effective](https://www.simplethread.com/why-your-website-should-not-use-dithered-images/) at reducing file size while preserving colors and detail than any form of dithering with reduced color depth. Nevertheless, dithering is still useful in some situations, and can also be used for aesthetic effect.

## How dithering works

We've seen how we can create different colors by mixing a few base colors—we'll call these _primaries_. In this section we'll explore different ways to decide where to mix which primaries to best reproduce the original, full-color image. To make things simpler and the effects of dithering clearer, we'll go back to pure black and white for the moment.

Dithering algorithms will be presented in pseudocode along an interactive demonstration of the results, following some conventions:

- `input` and `output` are image buffers. Pixels are read and set by `[x, y]` coordinates.
- Images are assumed to be grayscale unless otherwise specified. Grayscale pixel values are referred to as `value` and treated as numbers, while color pixel values are referred to as `color` and have `r`, `g`, and `b` number members.
- Values (grayscale or RGB) are in the range [0, 1].

The interactive demos will use this grayscale image:

<ImageGrid
  basePath="/Documents/Articles/assets/dither/"
  images={[
    {
      src: 'tram-original',
      formats: ['webp', 'jpeg'],
      alt: 'Original image',
    },
  ]}
/>

## Thresholding

Thresholding is the conversion to a reduced color range itself: the brightness or color values for each pixel are compared against a numerical _threshold_ to determine which color will be used. While not dithering in itself, all dithering methods do this at some point, so it's a good place to start.

The thresholding process for converting grayscale to black and white is very simple:

```
for (x, y) in input
  value = input[x, y]
  output[x, y] = if (value < t) 0; else 1
```

Where `t` is the threshold that controls whether a certain value should resolve to black or white. Try dragging the slider for `t` towards each end.

<DemoThreshold />

When dithering, we'll always use a balanced threshold value of 0.5.

## Random dithering

This is the simplest form of dithering: it just adds random noise to the image before reducing the colors. Random noise dithering code might look something like this:

```
for (x, y) in input
  value = input[x, y]
  noise = k * (random(0, 1) - 0.5)
  output[x, y] = if (value + noise < 0.5) 0; else 1
```

The parameter `k` controls the amplitude or “amount” of noise applied to the image. You can try it out below:

<DemoRandom />

This works because we're adding some “fuzziness” to the image, making some pixels pass the threshold when they normally wouldn't. Below is a visual demonstration of how noise dithering works.

The graph takes a one-dimensional “slice” of a flat gray color shown in the “target” box, placing brightness along the y axis. The white line indicates the threshold, while the points connected by the red line represent sampled points (in a real image, these would be pixels). The color of each point is its value after thresholding. The “sample average” box shows the average of all sampled points _after_ thresholding.

As you can see, for the initial brightness level of 35% the sample average is black, because 35% is less than the 50% threshold and so _all_ points become black. Try adding some noise by dragging the `k` slider all the way to the right:

<DemoRandomGraph />

As you add noise, some points go above the threshold and become white, bringing the average closer to the original 35% gray. Because the noise is “centered” around the original brightness, the average value will tend to get closer to the value as you add more samples. Try playing around with different brightness levels, noise levels, and sample sizes before moving on.

The problem with this approach becomes clear by looking at the results: among other things, it just looks bad. While adding random noise does help approximate the right proportions of black and white for each part of the image, it drowns out most details and the results are, expectedly, noisy. We can do better.

## Error diffusion

Error diffusion dithering is simple in principle and very effective. Instead of just adding noise at random, we measure the _error_ for a pixel (how much we “missed” by when assigning a primary), and then distribute or _diffuse_ that error along adjacent pixels. This way if we made a pixel darker than it should be, we'll make the adjacent pixels a little brighter to compensate, and viceversa. An error diffusion algorithm might look something like this:

```
number[x, y] errorMap // Error for each pixel, initialized to zero

for (x, y) in input
  value = input[x, y] + errorMap[x, y]
  output[x, y] = if (value < 0.5) 0; else 1

  error = value - output[x, y]

  // Error diffusion across pixels to the right and below
  errorMap[x + 1, y] = error / 2
  errorMap[x, y + 1] = error / 2
```

The result looks like this (Click to view in detail):

<ImageGrid
  size="lg"
  basePath="/Documents/Articles/assets/dither/"
  images={[
    {
      src: 'tram-original',
      formats: ['webp', 'jpeg'],
      alt: 'Original image',
      caption: 'Original image',
    },
    {
      src: 'tram-ed-simple',
      formats: ['webp', 'jpeg'],
      alt: 'Error Diffusion dithered',
      caption: 'Error Diffusion dithering',
    },
  ]}
/>

While there are still noticeable patterns, this is already much cleaner than simple random noise dithering. However, we can improve the error diffusion algorithm even further.

The above implementation uses an overly simplified _diffusion pattern_: half the error is propagated to the pixel to the right, half to the pixel below. If we were to draw it as a matrix, it would look something like this:

```
* 1
1 .

(/2)
```

Where `*` is the source pixel, and each number represents the portion of error propagated to that pixel. `(/2)` indicates that all numbers are divided by two.

In practice, more complex diffusion patterns are used to achieve better results. Patterns that distribute error across more pixels usually result in a smoother image. You can compare some of the most popular ones below (click each image to view in detail):

<ImageGrid
  size="lg"
  basePath="/Documents/Articles/assets/dither/"
  images={[
    {
      src: 'tram-ed-fs',
      formats: ['webp', 'jpeg'],
      alt: 'Floyd-Steinberg',
      caption: 'Floyd-Steinberg',
    },
    {
      src: 'tram-ed-jjn',
      formats: ['webp', 'jpeg'],
      alt: 'Minimum Average Error',
      caption: 'Minimum Average Error',
    },
    {
      src: 'tram-ed-stucki',
      formats: ['webp', 'jpeg'],
      alt: 'Stucki',
      caption: 'Stucki',
    },
    {
      src: 'tram-ed-sierra',
      formats: ['webp', 'jpeg'],
      alt: 'Sierra',
      caption: 'Sierra',
    },
  ]}
/>

Error diffusion is a much better algorithm than simple random noise, and is often used for dithering static images. It works especially well with very large color palettes, for example when reducing a camera's 14-bit image to standard 8-bit color. It's not without its drawbacks, however. With limited palettes, error diffusion dithering can produce very visible noise, color bands and “ghosts” as seen in the image below:

<ImageGrid
  basePath="/Documents/Articles/assets/dither/"
  images={[
    {
      src: 'flower',
      formats: ['webp', 'jpeg'],
      alt: 'Error dithering artifacts',
    },
  ]}
/>

The other major drawback is related to the way error diffusion works: because the final value of a pixel depends on every single pixel that came before it, it can't be used with parallel processing (for instance in GPUs). This makes it rather slow to compute in real time, which is why you didn't see any interactive examples in this section.

Also because of this, it doesn't work very well for animation or video, as a single pixel change can make the entire image shift around:

<ImageGrid
  size="lg"
  basePath="/Documents/Articles/assets/dither/"
  images={[
    {
      src: 'tram-motion-original',
      formats: ['gif'],
      alt: 'Error dithering animation',
      caption: 'Original animation, with a single moving pixel',
    },
    {
      src: 'tram-motion-ed',
      formats: ['webp', 'gif'],
      alt: 'Error dithering animation',
      caption: 'Noise patterns shift throughout the image',
    },
  ]}
/>

Next up, we'll look at a dithering method that solves these issues.

## Ordered dithering

An ordered dithering algorithm solves the problems of error diffusion by making the calculations for each pixel entirely independent from each other. We can use the random noise example from earlier as a starting point:

```
for (x, y) in input
  value = input[x, y]
  noise = k * (random(0, 1) - 0.5)
  output[x, y] = if (value + noise < 0.5) 0; else 1
```

<DemoRandom />

This algorithm is stateless: it doesn't keep any internal state, and operates on each pixel independently. In other words, there's no code outside the main pixel loop.

This example can be rewritten to think of the noise as adding to the _threshold_, rather than the input:

```
for (x, y) in input
  value = input[x, y]
  noise = k * (random(0, 1) - 0.5)
  threshold = 0.5 + noise
  output[x, y] = if (value < threshold) 0; else 1
```

This method is already very close to ordered dithering. Ordered dithering differs from our random noise example in that the threshold is sampled from a predetermined _threshold map_, rather than calculated randomly:

```
number[n, m] thresholdMap // Threshold map of size n * m
// Initialize threshold map with some values

for (x, y) in input
  value = input[x, y]
  threshold = thresholdMap[x % n, y % m]
  output[x, y] = if (value < threshold) 0; else 1
```

We also lose the parameter `k`, which controls the noise profile in the previous example. Here, the threshold map provides all the information we need.

The threshold map doesn't need to be the same size as the image: it is “tiled” as many times as necessary in both dimensions. This leaves only the matter of filling our threshold map with some values.

### Understanding threshold maps

To understand what threshold maps are and why they work, let's go back to the very first example with the black and white tiles. Try dragging the slider all the way to the right:

<DemoPattern showRatio="Brightness" initialRatio={0} />

As the amount of white pixels increases, the entire square becomes brighter. The square is 16 (4×4) pixels in size and has a total of 17 possible brightness levels, from no white pixels to all 16.

Knowing this, if we can reduce our image to 4×4 pixel tiles and 17 brightness levels, we can assign a pattern to each possible brightness:

<DemoPatternImage />

<div className="note">
  You might notice the image looks too bright and washed out when using the
  patterns. This happens because we're not doing any *gamma correction*. What
  gamma correction is and why it's necessary will be explained in the next
  article in this series.
</div>

The problem with this approach is we lose a lot of resolution: As long as we assign one pattern per tile, the number of brightness levels is limited by the size of the tiles. Instead, we can reduce the tile size, and have the 4×4 pattern cover multiple tiles. Try changing the tile size to 2×2 or even 1×1:

<DemoPatternImage showSizeRadio />

At a tile size of 1×1, each tile covers a single pixel—there is no resolution loss at all! This is how ordered dithering works: each pixel takes its color from a different part of the repeating pattern, depending on its own value.

### Threshold map patterns

Let's go back to the grid example one last time. Drag the slider slowly towards the highest brightness, paying attention to the position of white pixels:

<DemoPattern showZoom showRatio="Brightness" initialRatio={0} />

As you increase brightness, white pixels start appearing in a certain pattern. We can see the pattern more clearly by painting each tile with the brightness it needs to be “turned on”—in other words, its _threshold_—instead of white:

<DemoPattern showZoom showPattern showRatio="Brightness" initialRatio={0} />

The pattern you see in this last example with brightness turned all the way up is the actual threshold map. Try zooming out to see it repeating.

This pattern is a 4×4 [bayer matrix](https://en.wikipedia.org/wiki/Ordered_dithering#Threshold_map), a common threshold map for ordered dithering. It is a mathematically defined matrix of size N × M, containing all values in the range `[0; M × N)` such that each number is as far as possible from its immediate succesor. For example, the smallest 2×2 bayer matrix is

```
0 3
2 1
```

For dithering, the matrix is normalized: every value is divided by `N × M`, so we get threshold values between 0 and 1. Ordered dithering with a bayer matrix is mathematically very accurate, but produces noticeable artifacts in the form of a characteristic cross-hatch pattern. You can try out different matrix sizes below:

<DemoOrdered
  type="bayer"
  sizes={[
    { value: '2', name: '2×2' },
    { value: '4', name: '4×4' },
    { value: '8', name: '8×8' },
  ]}
/>

The cross-hatch pattern produced by a bayer matrix can sometimes be desirable for aesthetic reasons, but might also be unwanted. In these cases, a threshold map without any discernible patterns would be best. Random white noise, as we've seen, doesn't work. Ideally we want something with as few “large scale” or low-frequency patterns as possible: blue noise.

[Generating blue noise](http://momentsingraphics.de/BlueNoise.html) is outside the scope of this article. For our purposes, we can just use pre-generated blue noise textures as a threshold map (the [linked site](http://momentsingraphics.de/BlueNoise.html) has plenty available to download). You can try out ordered dithering with a blue noise threshold map below:

<DemoOrdered
  type="blueNoise"
  sizes={[
    { value: '16', name: '16×16' },
    { value: '64', name: '64×64' },
  ]}
  initial="64"
/>

Other patterns can be used as well—there's no restriction to what can be in a threshold map. For example, it can be used to form a coarse, halftone-like pattern:

<DemoOrdered
  type="halftone"
  sizes={[
    { value: '4', name: '4×4' },
    { value: '6', name: '6×6' },
    { value: '8', name: '8×8' },
  ]}
/>

Ordered dithering is the most versatile method: it can be used with any number of patterns to achieve different looks, and because each pixel is processed independently it is ideal for animation or moving images. The algorithm can also be implemented on the GPU, which makes real-time dithering feasible.

## Conclusion

So far, we've learned what dithering is, why it's useful (or fun), and how it works. In the next part, we'll explore how we can expand our dithering algorithms to work in color, with an arbitrary set of primaries or _color palette_.
